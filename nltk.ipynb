{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[(list(movie_reviews.words(fileid)),category)\n",
    "          for category in movie_reviews.categories()\n",
    "          for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words=nltk.FreqDist(all_words)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_features=list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words=set(document)\n",
    "    features={}\n",
    "    for w in words_features:\n",
    "        features[w]=(w in words)\n",
    "    return features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets=[(find_features(rev),category) for (rev,category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set=featuresets[:1900]\n",
    "testing_set=featuresets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algo accuracy percent:  78.0\n",
      "Most Informative Features\n",
      "               atrocious = True              neg : pos    =     11.8 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.9 : 1.0\n",
      "                bothered = True              neg : pos    =      9.1 : 1.0\n",
      "                 frances = True              pos : neg    =      8.9 : 1.0\n",
      "                  annual = True              pos : neg    =      8.9 : 1.0\n",
      "           unimaginative = True              neg : pos    =      8.5 : 1.0\n",
      "             silverstone = True              neg : pos    =      7.8 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.6 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.5 : 1.0\n",
      "                  shoddy = True              neg : pos    =      7.1 : 1.0\n",
      "                  regard = True              pos : neg    =      6.9 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.7 : 1.0\n",
      "                   kudos = True              pos : neg    =      6.5 : 1.0\n",
      "                    mena = True              neg : pos    =      6.4 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Naive Bayes Algo accuracy percent: \", (nltk.classify.accuracy(classifier,testing_set))*100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk is mainly for data preprocessing, now we are going to marry nltk with sklearn and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Algo accuracy percent:  79.0\n"
     ]
    }
   ],
   "source": [
    "multinomial_classifier=SklearnClassifier(MultinomialNB())\n",
    "multinomial_classifier.train(training_set)\n",
    "print(\"Multinomial Algo accuracy percent: \", (nltk.classify.accuracy(multinomial_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now using other ml classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Algo accuracy percent:  81.0\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier= SklearnClassifier(LogisticRegression())\n",
    "logistic_classifier.train(training_set)\n",
    "print(\"Logistic Algo accuracy percent: \", (nltk.classify.accuracy(logistic_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\incep\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Algo accuracy percent:  76.0\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier= SklearnClassifier(SGDClassifier())\n",
    "sgd_classifier.train(training_set)\n",
    "print(\"SGD Algo accuracy percent: \", (nltk.classify.accuracy(sgd_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Algo accuracy percent:  84.0\n"
     ]
    }
   ],
   "source": [
    "svc_classifier= SklearnClassifier(SVC())\n",
    "svc_classifier.train(training_set)\n",
    "print(\"SVC Algo accuracy percent: \", (nltk.classify.accuracy(svc_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearVC Algo accuracy percent:  77.0\n"
     ]
    }
   ],
   "source": [
    "lsvc_classifier= SklearnClassifier(LinearSVC())\n",
    "lsvc_classifier.train(training_set)\n",
    "print(\"LinearVC Algo accuracy percent: \", (nltk.classify.accuracy(lsvc_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC Algo accuracy percent:  82.0\n"
     ]
    }
   ],
   "source": [
    "nusvc_classifier= SklearnClassifier(NuSVC())\n",
    "nusvc_classifier.train(training_set)\n",
    "print(\"NuSVC Algo accuracy percent: \", (nltk.classify.accuracy(nusvc_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we are going to make a custom classifier combining several classifiers and taking the best vote score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self,*classifiers):\n",
    "        self.classifiers=classifiers\n",
    "    def classify(self,features):\n",
    "        vote=[]\n",
    "        for c in self.classifiers:\n",
    "            v=c.classify(features)\n",
    "            vote.append(v)\n",
    "        return mode(vote)   \n",
    "    def confidence(self,features):\n",
    "        vote=[]\n",
    "        for c in self.classifiers:\n",
    "            v=c.classify(features)\n",
    "            vote.append(v)\n",
    "        choice_votes=vote.count(mode(vote)) \n",
    "        conf= choice_votes/len(vote)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted Algo accuracy percent:  83.0\n"
     ]
    }
   ],
   "source": [
    "voted_classifier=VoteClassifier(logistic_classifier,svc_classifier,nusvc_classifier,nusvc_classifier,multinomial_classifier)\n",
    "print(\"Voted Algo accuracy percent: \", (nltk.classify.accuracy(voted_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification:neg actual result:pos confidence:1.0\n",
      "classification:pos actual result:pos confidence:1.0\n",
      "classification:neg actual result:neg confidence:1.0\n",
      "classification:pos actual result:neg confidence:1.0\n",
      "classification:pos actual result:pos confidence:1.0\n"
     ]
    }
   ],
   "source": [
    "print('classification:'+str(voted_classifier.classify(testing_set[0][0]))+' actual result:'+str(testing_set[0][1])+' confidence:'+str(voted_classifier.confidence(testing_set[0][0])))\n",
    "print('classification:'+str(voted_classifier.classify(testing_set[1][0]))+' actual result:'+str(testing_set[1][1])+' confidence:'+str(voted_classifier.confidence(testing_set[1][0])))\n",
    "print('classification:'+str(voted_classifier.classify(testing_set[2][0]))+' actual result:'+str(testing_set[2][1])+' confidence:'+str(voted_classifier.confidence(testing_set[2][0])))\n",
    "print('classification:'+str(voted_classifier.classify(testing_set[3][0]))+' actual result:'+str(testing_set[3][1])+' confidence:'+str(voted_classifier.confidence(testing_set[3][0])))\n",
    "print('classification:'+str(voted_classifier.classify(testing_set[4][0]))+' actual result:'+str(testing_set[4][1])+' confidence:'+str(voted_classifier.confidence(testing_set[4][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
